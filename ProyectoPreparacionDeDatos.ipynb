{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05390624-0a13-47a7-b042-c4a3912f0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pd.options.display.max_rows = 20 #Para controlar cuantas filas de los dataframes mostrar.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Para ignorar (o no) las advertencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73de6d73-a6a1-4f57-b25e-18b49e379f72",
   "metadata": {},
   "source": [
    "**AQUÍ SOLO SE MUESTRAN TRATAMIENTOS QUE HAY QUE HACERLE A LOS DATOS CON SUS RESPECTIVOS RESULTADOS. NO OBSTANTE, LUEGO HAY QUE METER ESTO EN UN COLUMN TRANSFORMER Y DESPUÉS EN UNA PIPELINE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb0afb-1a39-4d82-acb9-4d0ad0514ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero, leemos el archivo csv. Está separado por puntos y comas.\n",
    "\n",
    "datos = pd.read_csv('pokemon-data.csv',delimiter =';')\n",
    "y = datos.loc[:,'Tier'].copy()\n",
    "X = datos.loc[:,datos.columns != 'Tier'].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f7bed02-efeb-4b6f-a471-7f1e7a91b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a modificar el índice de las filas\n",
    "X.index = X['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf76a4-db7c-44da-85c4-3b81f70600b2",
   "metadata": {},
   "source": [
    "Esto es un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f940960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TierCathegorizer(TransformerMixin):\n",
    "    def transform(self,X,y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        yaux = X.copy()\n",
    "        tiers = np.where(np.logical_or(yaux.loc[:,'Tier'] == 'OU', yaux.loc[:,'Tier'] == 'Uber', yaux.loc[:,'Tier'] == 'AG'),'bueno','malo')\n",
    "        yaux.loc[:,'Tier'] = tiers\n",
    "        return yaux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero, leemos el archivo csv. Está separado por puntos y comas.\n",
    "\n",
    "datos = pd.read_csv('pokemon-data.csv',delimiter =';')\n",
    "y = datos.loc[:,'Tier'].copy()\n",
    "X = datos.loc[:,datos.columns != 'Tier'].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f7bed02-efeb-4b6f-a471-7f1e7a91b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a modificar el índice de las filas\n",
    "X.index = X['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abdb984",
   "metadata": {},
   "source": [
    "Para reducir el numero de clases para la variable de salida, juntamos los Pokemons en \"Buenos\" y \"Malos\". La categoría de \"buenos\" va a ser nuestra categoría \"positiva\", ya que es la que menos ejemplos posee, pero a su vez es la más interesante, ya que los jugadores competitivos quieren saber qué Pokémon son los mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f940960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TierCathegorizer(TransformerMixin):\n",
    "    def transform(self,X,y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        yaux = X.copy()\n",
    "        tiers = np.where(np.logical_or(yaux.loc[:,'Tier'] == 'OU', yaux.loc[:,'Tier'] == 'Uber', yaux.loc[:,'Tier'] == 'AG'),'bueno','malo')\n",
    "        yaux.loc[:,'Tier'] = tiers\n",
    "        return yaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tier',TierCathegorizer())])\n",
    "y_transformed = pipe.transform(y)\n",
    "print(\"Malos: \"+str(y_transformed[y_transformed==\"malo\"].count()[0]))\n",
    "print(\"Buenos: \"+str(y_transformed[y_transformed==\"bueno\"].count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74033c8",
   "metadata": {},
   "source": [
    "Juntamos los movimientos en una nueva columna que está compuesta por el número de movimientos. Sin embargo, el Pokemon Smeargle es una excepción porque puede aprender todos los movimientos, pero esto no está reflejado en la base de datos (Aparece con sólo 10 movimientos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d99e874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovementCounter(TransformerMixin):\n",
    "    def transform(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        Xaux = X.copy()\n",
    "        Xaux['Moves'] = Xaux['Moves'].astype(str).str.count(',') + 1\n",
    "        Xaux.loc['Smeargle','Moves'] = 676\n",
    "        return Xaux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c68cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('Movement', MovementCounter())])\n",
    "X_Count = pipe.transform(X)\n",
    "X_Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39353061-20e5-4662-9fbc-826013188300",
   "metadata": {},
   "source": [
    "Nos interesa desdoblar las columnas de los tipos, ya que hay muchas combinaciones de tipos diferentes. Al desdoblar la columna de tipos, obtenemos dos variables que sólo pueden tener 18 categorías (tipo 2 tendrá 19 categorías ya que a los Pokémon que sólo tienen un tipo les asignaremos un segundo tipo \"nulo\"), lo cual nos va a dar más información sobre lo bueno que es cada tipo a la hora\n",
    "de  determinar el potencial competitivo de un Pokémon. Para ello, creamos una clase `TypeCategorizer()`que se va a encargar de esto. Tiene los métodos `fit` y `transform`para poder utilziarse en una *Pipeline*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ce1270b-8dd2-429d-8ed2-40695c31ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeCategorizer(TransformerMixin):\n",
    "    # Constructor de la clase\n",
    "    def __init__(self, columns=None): #Si recibimos algo\n",
    "        self.columns = columns\n",
    "\n",
    "    #Fit\n",
    "    def fit(self, X):\n",
    "        X=pd.DataFrame(X) #Por si recibiéramos un array de numpy\n",
    "        if self.columns == None:\n",
    "            self.columns=X.columns\n",
    "        return self\n",
    "\n",
    "    #Transform\n",
    "    def transform(self, X):\n",
    "        #Creamos una copia de X para no perder los datos originales\n",
    "        Xaux=X.copy()\n",
    "        #Accedemos a la columna de tipos, y rellenamos las columnas acorde\n",
    "        for c in self.columns:\n",
    "            caracteresAEliminar = [\"[\", \"]\", \"'\"]\n",
    "            for char in caracteresAEliminar:\n",
    "                Xaux.loc[:,c]= Xaux.loc[:,c].str.replace(char,'')\n",
    "            #Después, para los Pokémon que solo tienen un tipo, vamos a añadirles un segundo tipo \"nulo\"\n",
    "            Xaux[['Type 1', 'Type 2']] = Xaux.loc[:,c].str.split(',', expand=True) #Expand true para que cree dos nuevas columnas\n",
    "\n",
    "            #Por último, hay que borrar la columna de \"Types\" original\n",
    "            Xaux=Xaux.drop([\"Types\"], axis=1)\n",
    "        return Xaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dcdf32-1655-4d48-85ee-c6b6d5b32c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizadorDeTipos = TypeCategorizer(columns = [\"Types\"])\n",
    "categorizadorDeTipos.fit(X)\n",
    "X_ConTipos = categorizadorDeTipos.transform(X_Count)\n",
    "X_ConTipos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd60cc-63f3-4b66-8645-563eeb109dd6",
   "metadata": {},
   "source": [
    "Vamos a realizar el mismo tratamiento para las habilidades. Es decir, vamos a generar tres columnas, una por cada habilidad (un Pokémon puede tener 1,2 ó 3 habilidades de las que escoger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45911c12-652c-439d-b74c-7c89ec52aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCaracter(text, character):\n",
    "    apariciones=0\n",
    "    for char in text:\n",
    "        if char==character:\n",
    "            apariciones+=1\n",
    "    return apariciones\n",
    "\n",
    "class AbilityCategorizer(TransformerMixin):\n",
    "    # Constructor de la clase\n",
    "    def __init__(self, columns=None): #Si recibimos algo\n",
    "        self.columns = columns\n",
    "\n",
    "    #Fit\n",
    "    def fit(self, X):\n",
    "        X=pd.DataFrame(X) #Por si recibiéramos un array de numpy\n",
    "        if self.columns == None:\n",
    "            self.columns=X.columns\n",
    "        return self\n",
    "\n",
    "    #Transform\n",
    "    def transform(self, X):\n",
    "        #Creamos una copia de X para no perder los datos originales\n",
    "        Xaux=X.copy()\n",
    "        #Accedemos a la columna de habilidades, y modificamos las columnas acorde\n",
    "        for c in self.columns:\n",
    "            caracteresAEliminar = [\"[\", \"]\", \"'\"]\n",
    "            for char in caracteresAEliminar:\n",
    "                Xaux.loc[:,c]= Xaux.loc[:,c].str.replace(char,'')\n",
    "            #Para los Pokémon que tienen sólo una habilidad, vamos a añadirles dos habilidades nulas; y para los\n",
    "            #que tengan 2 habilidades, les añadimos una extra.\n",
    "            for poke in Xaux.loc[:,c].index:\n",
    "                if countCaracter(Xaux.loc[poke,c], \",\")==0:\n",
    "                    Xaux.loc[poke,c]=Xaux.loc[poke,c]+\", None, None\"\n",
    "                elif countCaracter(Xaux.loc[poke,c], \",\")==1:\n",
    "                    Xaux.loc[poke,c]=Xaux.loc[poke,c]+\", None\"\n",
    "            #Creamos tres columnas nuevas\n",
    "            Xaux[['Ability 1', 'Ability 2', 'Ability 3']] = Xaux.loc[:,c].str.split(',', expand=True)\n",
    "            #Por último, hay que borrar la columna de \"Abilities\" original\n",
    "            Xaux=Xaux.drop([\"Abilities\"], axis=1)\n",
    "        return Xaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964affe7-48a0-4b52-bdf7-0dd84463433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizadorDeHabilidades = AbilityCategorizer(columns = [\"Abilities\"])\n",
    "categorizadorDeHabilidades.fit(X_ConTipos)\n",
    "X_ConTiposHabilidades = categorizadorDeHabilidades.transform(X_ConTipos)\n",
    "X_ConTiposHabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b8c64-84bf-425c-9373-4a28d5a4874c",
   "metadata": {},
   "source": [
    "Los nombres de los Pokémon no tienen relevancia competitiva, por lo que simplemente vamos a aplicar una codificación ordinal sobre esta columnna. Previsiblemente, al realizar la selección de variables, esta variable no será escogida, pero de igual forma necesitamos codificarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810ff12-4e9a-4a51-b31b-59e8a6a80a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodificadorOrdinal = ce.OrdinalEncoder(cols=[\"Name\"])\n",
    "#La entrenamos con el DataFrame sin datos faltantes\n",
    "encodificadorOrdinal.fit(X_ConTiposHabilidades)\n",
    "#Hacemos la transformación\n",
    "X_ConTiposHabilidadesNombres=encodificadorOrdinal.transform(X_ConTiposHabilidades)\n",
    "X_ConTiposHabilidadesNombres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd763e83-e80b-4a71-b655-f890ece32c2e",
   "metadata": {},
   "source": [
    "La columna de \"siguientes evoluciones\" puede tener relevancia ya que los Pokémon que todavía pueden evolucionar pueden utilizar un objeto llamado Mineral Evolutivo, que aumenta sus defensas en un 50%. No nos importa tanto si el Pokémon puede evolucionar una vez, dos veces o si tiene diferentes posibles evoluciones; solo si es capaz de evolucionar. Por lo tanto, codificaremos esta columna de la siguiente manera: si el Pokémon tiene alguna evolución posible, le asignaremos el valor 1; en caso contrario, le asignaremos el valor 0. Para ello, vamos a modificar la columna aplicándole dos tratamientos. Si la fila correspondiente es \"[]\", pondremos \"´No\", y en caso contrario pondremos \"Si\". Después, aplicaremos una codificación One Hot, adecuada ya que sólo generará una columna adicional al poder tomar esta variable solo dos valores.\n",
    "\n",
    "Además, hay algunos Pokémon que pueden tener formas alternativas (que no se consideran evoluciones, por lo que no permiten el uso del Mineral Evolutivo) y que en el dataset presentan una lista no vacía en la columna de \"siguientes evoluciones\". Como no hay ningún criterio para detectar estos casos, los vamos a tratar manualmente. Estos Pokémon son **Giratina**, **Greninja**, **Kyurem**, **Landorus**, **Oricorio**, **Rotom**, **Shaymin**, **Thundurus**, **Tornadus** y **Zygarde**. Pese a que tengan una lista vacía, estos Pokémon los vamos a codificar como que **no** tienen evolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92900e43-7880-4beb-be7b-aa9b80580479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolutionCategorizer(TransformerMixin):\n",
    "    # Constructor de la clase\n",
    "    def __init__(self, columns=None): #Si recibimos algo\n",
    "        self.columns = columns\n",
    "\n",
    "    #Fit\n",
    "    def fit(self, X, y=0):\n",
    "        X=pd.DataFrame(X) #Por si recibiéramos un array de numpy\n",
    "        if self.columns == None:\n",
    "            self.columns=X.columns\n",
    "        return self\n",
    "\n",
    "    #Transform\n",
    "    def transform(self, X, y=0):\n",
    "        #Creamos una copia de X para no perder los datos originales\n",
    "        Xaux=X.copy()\n",
    "        #Accedemos a la columna de tipos, y rellenamos las columnas acorde\n",
    "        for c in self.columns:\n",
    "            Xaux.loc[:,c] = np.where(Xaux.loc[:,c]==\"[]\", \"No\", \"Si\")\n",
    "            #Ahora, consideramos las excepciones descritas arriba\n",
    "            pokemonEquivocados = [\"Giratina\", \"Greninja\", \"Kyurem\", \"Landorus\", \"Oricorio\", \"Rotom\", \"Shaymin\", \"Thundurus\", \"Tornadus\", \"Zygarde\"]\n",
    "            for poke in pokemonEquivocados:\n",
    "                Xaux.loc[poke,c]=\"No\"\n",
    "        return Xaux\n",
    "\n",
    "    #set_params\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "#Una vez aplicamos el EvolutionCategorizer(), aplicamos el One Hot Encoding. Para ello, hacemos una PipeLine\n",
    "pipe_Evol =  Pipeline([('Categorizador de Evoluciones', EvolutionCategorizer(columns=[\"Next Evolution(s)\"])), \n",
    "                       ('One Hot Encoding', ce.OneHotEncoder(cols = [\"Next Evolution(s)\"], handle_unknown=\"ignore\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1e9d6-3cb4-4a73-96ce-3e6bf593d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_Evol.fit(X_ConTiposHabilidadesNombres)\n",
    "datosTiposHabilidadesNombresEvol = pipe_Evol.transform(X_ConTiposHabilidadesNombres)\n",
    "datosTiposHabilidadesNombresEvol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e586aa64",
   "metadata": {},
   "source": [
    "Dividimos los datos en: Conjunto de entrenamiento, validación y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec74f79e-d137-4f5d-ac2c-77e0b3075f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de los conjuntos de test (10% de los ejemplos) y el resto de ejemplos\n",
    "restoEjemplos_X, X_test, restoEjemplos_y, y_test =  train_test_split(X.loc[:,:],y.loc[:], test_size=0.10, random_state=123)\n",
    "\n",
    "# Creación de los conjuntos de train (80% de los ejemplos) y de validación (resto de los ejemplos)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(restoEjemplos_X,restoEjemplos_y, train_size=0.80, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60baeb94",
   "metadata": {},
   "source": [
    "Buscamos Outliers entre los datos mediante el método del rango intercuartílico. Sin embargo, puede tener sentido no borrar los outliers debido a que las estadísticas de los Pokemons no son mediciones sino sus valores \"reales\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dfdf3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la clase de detección y tratamiento de Outliers\n",
    "class OutlierDetecion_treatment_IQR(TransformerMixin):\n",
    "    nombresVariablesNum = ['HP', 'Attack', 'Defense', 'Special Attack', 'Special Defense','Speed']\n",
    "    # Constructor de la clase\n",
    "    def __init__(self, k=1.5, columns=nombresVariablesNum):\n",
    "        self.k = k\n",
    "        self.columns = columns\n",
    "    \n",
    "    # Método fit\n",
    "    def fit(self, X, y=None):\n",
    "        # Transformamos X a DataFrame por si llega un array de Numpy (para compatibilidad en la Pipeline)\n",
    "        X = pd.DataFrame(X)\n",
    "        if self.columns == None:\n",
    "            # Si no se determinan variables en el constructor si tratan todas\n",
    "            self.columns = X.columns\n",
    "        self.stats = X.loc[:,self.columns].describe()\n",
    "        # Devolvemos el propio objeto modificado\n",
    "        return self\n",
    "\n",
    "    # Método transform\n",
    "    def transform(self, X):\n",
    "        # Transformamos X a DataFrame por si llega un array de Numpy (para compatibilidad en la Pipeline)\n",
    "        X = pd.DataFrame(X)\n",
    "        # Creamos una copia del DataFrame X para no perder los datos originales\n",
    "        Xaux = X.copy()\n",
    "        # Se calcula el IQR de cada variable\n",
    "        IQRs = self.stats.loc['75%'] - self.stats.loc['25%']\n",
    "        # Se calculan los límites inferiores y superiores   \n",
    "        limiteInf = self.stats.loc['25%'] - self.k * IQRs\n",
    "        limiteSup = self.stats.loc['75%'] + self.k * IQRs\n",
    "        # Se comprueba qué elementos están por encima y por debajo de dichos límites (máscaras de booleanos)  \n",
    "        print(limiteInf)\n",
    "        print(limiteSup)\n",
    "        menores = Xaux.loc[:,self.nombresVariablesNum] < limiteInf\n",
    "        mayores = Xaux.loc[:,self.nombresVariablesNum] > limiteSup\n",
    "\n",
    "        # Se recorren las variables para detectar outliers y tratarlos (sustituir por la mediana de la variable)\n",
    "        for c in self.columns:\n",
    "            # obtenemos la lista de booleanos correspondientes a si los valores de los ejemplos son outliers o no para la variable c\n",
    "            indices = np.logical_or(menores[c] , mayores[c])\n",
    "            # Si hay outliers\n",
    "            if indices.any():\n",
    "                # Los sustituimos por la mediana\n",
    "                print(\"Se han encontrado outliers en la variable\", c)\n",
    "                print(Xaux.loc[indices, c])\n",
    "                #Xaux.loc[indices, c] = self.stats.loc['50%', c]\n",
    "        # Se devuelve el DataFrame modificado\n",
    "        return Xaux\n",
    "    \n",
    "    # Método para asignar los valores de los híper-parámetros y que, de este modo, \n",
    "        # podamos aplicar GridSearchCV sobre un objeto de esta clase\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    # Método para obtener los valores de los híper-parámetros que queramos del modelo (lo usa GridSearchCV al mostrar la mejor configuración)\n",
    "    def get_params(self, deep=True):\n",
    "        # Devolvemos los valores de los híper-parámetros del método de preparación de datos\n",
    "        return {\"k\": self.k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf01e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos la clase anterior (llamamos out_IQR al objeto), la entrenamos con los datos de train y transformamos el conjunto de train\n",
    "out_IQR = OutlierDetecion_treatment_IQR(k = 3)\n",
    "out_IQR = out_IQR.fit(X_train)\n",
    "X_train_IQR = out_IQR.transform(X_train)\n",
    "print(X_train_IQR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
